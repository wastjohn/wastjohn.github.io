{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Persistent Images of Gravitionally Lensed Galaxies\"\n",
        "bibliography: bibliography.bib\n",
        "title-slide-attributes:\n",
        "    data-background-image: https://euclid.caltech.edu/download/AvmImage/58/binary/jpg_original\n",
        "\n",
        "format: html\n",
        "    \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Introduction\n",
        "Gravitationally lensed galaxies are an active area of research in astronomy as investigating their properties can give insights into gravitational\n",
        "\n",
        "\n",
        "## Astronomy\n",
        "- What is a gravitationally lensed galaxy?\n",
        "- Why do we care about them?\n",
        "\n",
        "## Persistent Homology\n",
        "- What is it?\n",
        "- How is it helpful?\n",
        "- How has it been used in astronomy before?\n",
        "- What do I plan \n",
        "\n",
        "## Machine Learning\n",
        "- What is machine learning?\n",
        "- Why do we need/want to perform clustering?\n",
        "- How do the clustering algorithms work and what are they?\n",
        "\n",
        "# Data\n",
        "The Euclid Space telescope was launched in ___ with the intention of mapping 2/3 of the night sky. On March 19, 2025, the Euclid Collaboration released their Quick Data Release (Q1).\n",
        "\n",
        "- What data do I have? What does it look like?\n",
        "- Where did I get the data from?\n",
        "- Who funded the data?  - ESA\n",
        "- When was the data collected?\n",
        "- Why was the data collected?\n",
        "- How do I plan on using the data?\n",
        "\n",
        "The code chunk below imports the necessary modules for working with this data.\n"
      ],
      "id": "9c151c96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from astroquery.esa.euclid import Euclid\n",
        "from astropy.coordinates import SkyCoord\n",
        "from astropy.wcs import WCS\n",
        "import astropy.units as u\n",
        "from astropy.io import fits\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.visualization import astropy_mpl_style, ImageNormalize, PercentileInterval, AsinhStretch, LogStretch\n",
        "import gtda.plotting\n",
        "import pandas as pd\n",
        "from astropy.io import ascii\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "from gtda.images import Binarizer\n",
        "from gtda.images import RadialFiltration\n",
        "from gtda.homology import CubicalPersistence\n",
        "from gtda.diagrams import Scaler\n",
        "from gtda.diagrams import PersistenceImage\n",
        "from persim import PersImage\n",
        "from persim import PersistenceImager"
      ],
      "id": "077470fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once all the libraries are imported, we can extract the data. Each lensed galaxy was found via a machine learning classification model, thus there existed a distribution of objects with associated probabilities that they were lensed galaxies, based on the model. Currently, this project only incorporates objects that had a \"grade\" of \"A\" (i.e. were of the best quality).\n"
      ],
      "id": "3ce4727e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get coordinates from list of targets (only select best images)\n",
        "all_targets = ascii.read(\"D:/data/targets/q1_discovery_engine_lens_catalog.csv\")\n",
        "mask = (all_targets[\"subset\"] == \"discovery_engine\") & (all_targets[\"grade\"] == \"A\")\n",
        "targets = all_targets[mask]"
      ],
      "id": "3be7fc88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The target list only contains the celestial coordinates of the grade-A lensed galaxies. Luckily, we can download cutouts of the targets. Note, this code chunk is intentially set to not run as all of the cutouts have already been extracted. Note, we have ~250 targets.\n"
      ],
      "id": "22d2e9fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | eval: false\n",
        "# don't run unless need redownload images!!!\n",
        "# download the images for each target\n",
        "empty_images = 0\n",
        "for i in range(len(targets)):\n",
        "    r, d = targets[\"right_ascension\"][i], targets[\"declination\"][i]\n",
        "    coord = SkyCoord(r, d, unit=u.deg, frame='icrs')\n",
        "    radius = u.Quantity(0.5, u.deg)\n",
        "\n",
        "    print(f\"r: {r}\")\n",
        "    print(f\"d: {d}\")\n",
        "    print(coord)\n",
        "    print(radius)\n",
        "\n",
        "    # search euclid's mosaic product catalog for targets\n",
        "    job = Euclid.cone_search(coordinate=coord, radius=radius, table_name=\"sedm.mosaic_product\", ra_column_name=\"ra\", dec_column_name=\"dec\", columns=\"*\", async_job=True, verbose=True)\n",
        "    cone_results = job.get_results()\n",
        "    example_file = cone_results[cone_results['instrument_name'] == 'VIS'][0]\n",
        "    print(f\"cone_results: {cone_results}\")\n",
        "\n",
        "    # save results to output path\n",
        "    file_path = example_file[\"file_path\"] + \"/\" + example_file[\"file_name\"]\n",
        "    instrument = example_file[\"instrument_name\"]\n",
        "    obs_id = example_file[\"tile_index\"]\n",
        "    radius = 0.1 * u.arcmin\n",
        "    output_folder = 'D:/data/'\n",
        "\n",
        "    print(f\"file_path: {file_path}\")\n",
        "    print(f\"instrument: {instrument}\")\n",
        "    print(f\"obs_id: {obs_id}\")\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    output_file=output_folder + f'cutouts_0.1arcmin/target_{r}_{d}.fits'\n",
        "    saved_cutout_filepath = Euclid.get_cutout(file_path=file_path,\n",
        "        instrument=instrument, id=obs_id, \n",
        "        coordinate=coord, radius=radius, output_file=output_file)\n",
        "\n",
        "    print(\"Cutout saved at\", output_file)\n",
        "\n",
        "    # looking at the cutout we made\n",
        "    try:\n",
        "        hdul = fits.open(output_file)\n",
        "        print(fits.info(output_file))\n",
        "        image_data = hdul[0].data\n",
        "        plt.imshow(image_data, interpolation='nearest', cmap='gray', origin='lower', norm=ImageNormalize(image_data, interval=PercentileInterval(99.5),\n",
        "                            stretch=AsinhStretch()))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "    except:\n",
        "        empty_images += 1\n",
        "\n",
        "print(empty_images)"
      ],
      "id": "52ed53e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the cutouts are extracted, we can display them so get a sense of what the data actually looks like. The code chunk below shows an example of what a gravitationally lensed galaxy looks like from the Euclid space telescope.\n"
      ],
      "id": "934e6144"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get data from each fits image\n",
        "fits_files_clean = glob.glob(\"D:/data/cutouts_0.1arcmin_119x119/*.fits\")\n",
        "\n",
        "data_list = []\n",
        "for file in fits_files_clean:\n",
        "    hdul = fits.open(file)\n",
        "    data = hdul[0].data\n",
        "    data_list.append(data)"
      ],
      "id": "a4d2ec4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis\n",
        "Once we have the images, the next step is to compute the persistent homology for each image. The code chunk below displays the example image using Python, a Giotto-tda heatmap mehtod, and calculates the cubical persistence of the example image.\n",
        "\n",
        "\n",
        "\n",
        "## FITS Image\n"
      ],
      "id": "828ea1a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load in the image\n",
        "plt.imshow(data_list[0].reshape((119, 119)), interpolation='nearest', cmap='gray', origin='lower', norm=ImageNormalize(data_list[0], interval=PercentileInterval(99.5), stretch=AsinhStretch()))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "id": "daa0626a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n"
      ],
      "id": "c7e6d8f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# rescaling to [0,1]\n",
        "scale = 10\n",
        "data_list = [data.reshape((1,119,119)) for data in data_list]  # reshape for cubical complex\n",
        "data_list = [scale * (data - data.min()) / (data.max() - data.min()) for data in data_list]  # rescale\n",
        "data_invert_list = [scale * np.ones(data.shape) - data for data in data_list]"
      ],
      "id": "7d94db6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# display preprocessed image\n",
        "plt.imshow(data_invert_list[0].reshape(119,119), interpolation='nearest', cmap='gray', origin='lower', norm=ImageNormalize(data_invert_list[0], interval=PercentileInterval(99.5), stretch=AsinhStretch()))\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "id": "0ce8fe3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Persistence\n"
      ],
      "id": "f16b2368"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cubical_persistence = CubicalPersistence(homology_dimensions=(0,1), n_jobs=-1, infinity_values=scale)\n",
        "\n",
        "print(\"calculating cubical persistence (h0) on inverted images...\")\n",
        "cubical_invert_data_list = []\n",
        "for inverted_data in data_invert_list:\n",
        "    cubical_invert_data = cubical_persistence.fit_transform(inverted_data)\n",
        "    cubical_invert_data_list.append(cubical_invert_data)\n",
        "\n",
        "print(\"calculating cubical persistence (h1) on images...\")\n",
        "cubical_data_list = []\n",
        "for data in data_list:\n",
        "    cubical_data = cubical_persistence.fit_transform(data)\n",
        "    cubical_data_list.append(cubical_data)"
      ],
      "id": "3069c5a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cubical_diagram0_list = []\n",
        "for cubical_invert_data in cubical_invert_data_list:\n",
        "    mask0 = cubical_invert_data[:,:,2] == 0  # id h0 in inverted data\n",
        "    data_cubical0 = cubical_invert_data[mask0]  # select h0 inverted data\n",
        "    cubical_diagram0 = np.delete(data_cubical0, 2, 1)  # remove the h0 identifier\n",
        "    cubical_diagram0_list.append(cubical_diagram0)  # add to list\n",
        "\n",
        "cubical_diagram1_list = []\n",
        "for cubical_data in cubical_data_list:\n",
        "    mask1 = cubical_data[:,:,2] == 1  # id h1 in inverted data\n",
        "    data_cubical1 = cubical_data[mask1]  # select h1 inverted data\n",
        "    cubical_diagram1 = np.delete(data_cubical1, 2, 1)  # remove the h1 identifier\n",
        "    cubical_diagram1_list.append(cubical_diagram1)  # add to list"
      ],
      "id": "518c357b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Persistence Images\n"
      ],
      "id": "ae42d0d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# fit h0 images\n",
        "h0_pimgr = PersistenceImager(pixel_size=1)\n",
        "h0_pimgr.weight_params = {\"n\": 1.5}  # tuning parameter (maybe [1, 2])\n",
        "h0_pimgr.fit(cubical_diagram0_list)\n",
        "h0_pimgr.birth_range = (0, scale)\n",
        "h0_pimgr.pers_range = (0, scale)\n",
        "h0_imgs = h0_pimgr.transform(cubical_diagram0_list, skew=True)\n",
        "\n",
        "# fit h1 images\n",
        "h1_pimgr = PersistenceImager(pixel_size=1)\n",
        "h1_pimgr.weight_params = {\"n\": 1.5}  # tuning parameter (maybe [1, 2])\n",
        "h1_pimgr.fit(cubical_diagram1_list)\n",
        "h1_pimgr.birth_range = (0, scale)\n",
        "h1_pimgr.pers_range = (0, scale)\n",
        "h1_imgs = h1_pimgr.transform(cubical_diagram1_list, skew=True)"
      ],
      "id": "3b2db1ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def persistence_diagram(bdh_array, ax): \n",
        "    h0mask = bdh_array[:,:,2] == 0\n",
        "    h1mask = bdh_array[:,:,2] == 1\n",
        "    h0birth = bdh_array[h0mask][:,0] \n",
        "    h0death = bdh_array[h0mask][:,1]\n",
        "    h1birth = bdh_array[h1mask][:,0] \n",
        "    h1death = bdh_array[h1mask][:,1]\n",
        "\n",
        "    ax.scatter(h0birth, h0death, alpha=0.5, marker='.', label=\"h0\")\n",
        "    ax.scatter(h1birth, h1death, alpha=0.5, marker='.', label=\"h1\")\n",
        "    ax.set_xlabel(\"Birth\")\n",
        "    ax.set_ylabel(\"Death\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    oldxlim = ax.get_xlim()\n",
        "    oldylim = ax.get_ylim()\n",
        "    ax.axline((0,0), (scale + 1,scale + 1), linestyle='--', c=\"grey\")\n",
        "    ax.set_xlim(-0.5, scale + 0.5)\n",
        "    ax.set_ylim(-0.5, scale + 0.5)\n",
        "    return\n",
        "\n",
        "\n",
        "def pipeline_plot(index: str = 0, return_fig: bool = False):\n",
        "    fig, ax = plt.subplots(2,3,figsize=(10,8))\n",
        "    # inverted image\n",
        "    im_invert = ax[0][0].imshow(data_invert_list[index].reshape((119, 119)), interpolation='nearest', cmap='gray', origin='lower', norm=ImageNormalize(data_invert_list[index], interval=PercentileInterval(99.5), stretch=AsinhStretch()))\n",
        "    ax[0][0].set_title(\"Raw Image (Inverted)\")\n",
        "    fig.colorbar(im_invert, ax=ax[0][0])\n",
        "\n",
        "    # persistence diagram (inverted)\n",
        "    persistence_diagram(cubical_invert_data_list[index], ax[0][1])\n",
        "    ax[0][1].set_title(\"H0 Persistence Diagram (Inverted Data)\")\n",
        "\n",
        "    # persistence image (inverted)\n",
        "    h1_pimgr.plot_image(h1_imgs[index], ax=ax[0][2])\n",
        "    ax[0][2].set_title(\"H0 Persistence Image (Inverted Data)\")\n",
        "\n",
        "    # raw image\n",
        "    im = ax[1][0].imshow(data_list[index].reshape((119, 119)), interpolation='nearest', cmap='gray', origin='lower', norm=ImageNormalize(data_list[index], interval=PercentileInterval(99.5), stretch=AsinhStretch()))\n",
        "    ax[1][0].set_title(\"Raw Image\")\n",
        "    fig.colorbar(im, ax=ax[1][0])\n",
        "\n",
        "    # persistence diagram (normal)\n",
        "    persistence_diagram(cubical_data_list[index], ax[1][1])\n",
        "    ax[1][1].set_title(\"H1 Persistence Diagram\")\n",
        "\n",
        "    # persistence image (normal)\n",
        "    h0_pimgr.plot_image(h0_imgs[index], ax=ax[1][2])\n",
        "    ax[1][2].set_title(\"H1 Persistence Image\")\n",
        "\n",
        "    # adjust subplot images\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
        "\n",
        "    if return_fig:\n",
        "        return fig, ax\n",
        "    \n",
        "    return"
      ],
      "id": "a7cad937",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipeline_plot(-12)"
      ],
      "id": "d7bc938a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# convert to vector\n",
        "h0_vec = [image.reshape(100) for image in h0_imgs]\n",
        "h1_vec = [image.reshape(100) for image in h1_imgs]\n",
        "\n",
        "final_vec = []\n",
        "for i in range(len(h0_vec)):\n",
        "    combined = np.concatenate((h0_vec[i], h1_vec[i]), axis=None)\n",
        "    final_vec.append(combined)"
      ],
      "id": "5cade569",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Original Images to Vectors and Save Both Vectors to a CSV \n"
      ],
      "id": "85c4729d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fits_files = glob.glob(\"D:/data/cutouts_0.1arcmin/*.fits\")\n",
        "names = [i.split(\"\\\\\")[-1].replace('.fits', \"\") for i in fits_files]\n",
        "\n",
        "final_table = pd.DataFrame(np.vstack(final_vec), index=names)\n",
        "final_table.to_csv(\"D:/results/persistent_results.csv\")\n",
        "\n",
        "fits_image_vec = [image.reshape(119 * 119) for image in data_list]\n",
        "final_fits_table = pd.DataFrame(np.vstack(fits_image_vec), index=names)\n",
        "final_fits_table.to_csv(\"D:/results/fits_results.csv\")"
      ],
      "id": "95b41c39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering\n",
        "\n",
        "Hierarchical clustering.\n",
        "\n",
        "\n",
        "# Results and Discussion\n",
        "\n",
        "\n",
        "## Cluster: Natural Images {.center .nonincremental}\n",
        "\n",
        "![](cluster_natural.png){.fragment width=\"1200\" height=\"600\"}\n",
        "\n",
        "## Cluster: Persistence Images {.center .nonincremental}\n",
        "\n",
        "![](cluster_persistent.png){.fragment width=\"1600\" height=\"600\"}\n",
        "\n",
        "\n",
        "## {.center}\n",
        "\n",
        "![](cluster_persistent.png){.fragment width=\"1600\" height=\"600\"}\n",
        "\n",
        "# Conclusions\n",
        "\n",
        "# References\n",
        "blah blah [@Chen2015, @Sousbie2011]"
      ],
      "id": "e815171c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\qwert\\anaconda3\\envs\\pyscope-dev\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}